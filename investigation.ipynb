{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests \n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"D:\\GitHub\\Incursion-Damage-Mods\\webcrawler\\HeatSinkOutput.csv\")\n",
    "df2 = pd.read_csv(\"D:\\GitHub\\Incursion-Damage-Mods\\webcrawler\\MagStabOutput.csv\")\n",
    "df3 = pd.read_csv(\"D:\\GitHub\\Incursion-Damage-Mods\\webcrawler\\GyroStabOutput.csv\")\n",
    "\n",
    "df_merge = pd.concat([df1, df2], ignore_index=True)\n",
    "df_merge = pd.concat([df_merge, df3], ignore_index=True)\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://esi.evetech.net/latest/universe/regions/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "region_ids = response.json()\n",
    "print(f\"Regions to scan: {len(region_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contracts = []\n",
    "for region_id in region_ids:\n",
    "    total_pages = 1\n",
    "    current_page = 1\n",
    "    base_url = \"https://esi.evetech.net/latest/contracts/public/{}/\".format(region_id)\n",
    "    params = {\"datasource\": \"tranquility\", \"page\": current_page}\n",
    "    \n",
    "    while params[\"page\"] <= total_pages:\n",
    "        print(base_url)\n",
    "        print(params)\n",
    "        response = requests.get(base_url, params=params)\n",
    "        print(response.headers)\n",
    "        print(response)\n",
    "        if total_pages == 1:\n",
    "            total_pages = int(response.headers.get(\"X-Pages\"))\n",
    "            \n",
    "        if response.status_code == 200:\n",
    "            raw_contracts = response.json()\n",
    "            item_exchange_contracts = [contract for contract in raw_contracts if contract[\"type\"] == \"item_exchange\"]\n",
    "            contracts.extend(item_exchange_contracts)\n",
    "            params[\"page\"] += 1\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected API Response\")\n",
    "        if \"ETag\" not in params:\n",
    "            params[\"ETag\"] = response.headers.get(\"ETag\").strip('\\\"')    \n",
    "        \n",
    "\n",
    "pd.json_normalize(contracts).to_parquet(\"./api_database/contracts.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contracts = pd.read_parquet(\"./api_database/contracts.parquet\")[[\"contract_id\", \"date_issued\"]]\n",
    "\n",
    "known_abyssal_contracts = pd.read_parquet(\"./api_database/item_stats.parquet\")\n",
    "known_abyssal_contracts_agg = known_abyssal_contracts.groupby(\"contract_id\", as_index=False).agg({\n",
    "    \"item_id\": \"nunique\"\n",
    "}).rename(columns={\"item_id\":\"abyssal_count\"})\n",
    "\n",
    "df_contracts = df_contracts.merge(known_abyssal_contracts_agg,how=\"left\", on =\"contract_id\")\n",
    "df_contracts[\"date_issued\"] = pd.to_datetime(df_contracts[\"date_issued\"])\n",
    "df_contracts = df_contracts[(df_contracts[\"date_issued\"] > (pd.to_datetime(datetime.utcnow() - timedelta(days=1)).tz_localize(\"UTC\"))) | (df_contracts[\"abyssal_count\"] > 0)][[\"contract_id\"]]\n",
    "\n",
    "last_run_items = pd.read_parquet(\"./api_database/contract_items.parquet\")\n",
    "last_run_contracts = last_run_items.groupby(\"contract_id\", as_index=False).agg({\n",
    "    \"updated_at\": \"max\"\n",
    "})\n",
    "\n",
    "contracts_to_scan = df_contracts.merge(last_run_contracts, how=\"left\", on=\"contract_id\")\n",
    "contracts_to_scan = contracts_to_scan[(contracts_to_scan[\"updated_at\"] < (pd.to_datetime(\"today\") + pd.DateOffset(hours=-12))) | (contracts_to_scan[\"updated_at\"].isna())] [\"contract_id\"].drop_duplicates(keep=\"first\").tolist()\n",
    "\n",
    "last_run_items = last_run_items.merge(df_contracts[[\"contract_id\"]].drop_duplicates(keep=\"first\"), how=\"inner\", on=\"contract_id\")\n",
    "contracts_scanned = last_run_items[last_run_items[\"updated_at\"] > (pd.to_datetime(\"today\") + pd.DateOffset(hours=-12))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contracts_to_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "contract_count = 0\n",
    "print (len(contracts_to_scan))\n",
    "for contract_id in contracts_to_scan:\n",
    "    total_pages = 1\n",
    "    page = 1\n",
    "    while page <= total_pages:\n",
    "        contract_count += 1\n",
    "        base_url = \"https://esi.evetech.net/latest/contracts/public/items/{}/\".format(contract_id)\n",
    "        params = {\"datasource\": \"tranquility\", \"page\": page}\n",
    "                \n",
    "        print(base_url)\n",
    "        print(params)\n",
    "        print(contract_count)\n",
    "        response = requests.get(base_url, params=params)\n",
    "        print(response.headers)\n",
    "        print(response)\n",
    "        if (total_pages == 1) & (response.headers.get(\"X-Pages\") != None):\n",
    "            total_pages = int(response.headers.get(\"X-Pages\"))\n",
    "            print(total_pages)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            if response.text != \"\":\n",
    "                raw_contract_items = response.json()\n",
    "                contract_items = [contract_item for contract_item in raw_contract_items]\n",
    "                print(f\"Items found: {len(contract_items)}\")\n",
    "                for contract_item in contract_items:\n",
    "                    contract_item[\"contract_id\"] = contract_id\n",
    "                    contract_item[\"updated_at\"] = datetime.utcnow()\n",
    "                items.extend(contract_items)\n",
    "        else:\n",
    "            if int(response.headers.get(\"X-Esi-Error-Limit-Remain\", 100)) < 20:\n",
    "                break\n",
    "            elif int(response.headers.get(\"X-Esi-Error-Limit-Remain\", 50)) < 50:\n",
    "                time.sleep(60)\n",
    "        page += 1\n",
    "\n",
    "contracts_scanned = pd.concat([contracts_scanned, pd.json_normalize(items)],ignore_index=True)\n",
    "contracts_scanned.to_parquet(\"./api_database/contract_items.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_abyssal_contracts = pd.read_parquet(\"./api_database/item_stats.parquet\")\n",
    "known_abyssal_contracts_agg = known_abyssal_contracts.groupby([\"contract_id\"], as_index=False).agg({\n",
    "    \"item_id\": \"nunique\"\n",
    "}).rename(columns={\"item_id\":\"item_id_count\"})\n",
    "\n",
    "# Clean up affteragg data TODO\n",
    "contract_items = pd.read_parquet(\"./api_database/contract_items.parquet\")\n",
    "contract_items = contract_items.merge(known_abyssal_contracts_agg, how=\"left\", on=[\"contract_id\"])\n",
    "contract_items_to_scan = contract_items[(contract_items[\"item_id_count\"].isna()) & (contract_items[\"item_id\"].notna())]\n",
    "contract_items_to_scan[\"item_id\"] = contract_items_to_scan[\"item_id\"].astype(\"int64\")\n",
    "contract_items_to_scan[\"item_idtype_id\"] = contract_items_to_scan[\"type_id\"].astype(\"int64\")\n",
    "\n",
    "contract_items_scanned = contract_items[(contract_items[\"item_id_count\"].notna())]\n",
    "# contract_items_scanned = known_abyssal_contracts.merge(contract_items_scanned[[\"contract_id\"]].drop_duplicates(keep=\"first\"), how=\"inner\", on=\"contract_id\")\n",
    "contract_items_scanned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_stats = []\n",
    "\n",
    "for index, row in contract_items_to_scan.iterrows():\n",
    "    if row[\"type_id\"] in [49726, 49722, 49730]:\n",
    "        base_url = f\"https://esi.evetech.net/latest/dogma/dynamic/items/{row['type_id']}/{row['item_id']}/\"\n",
    "        params = {\"datasource\": \"tranquility\"}\n",
    "        print(base_url)\n",
    "        print(params)\n",
    "        response = requests.get(base_url, params=params)\n",
    "        print(response.headers)\n",
    "        print(response)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            row_info = response.json()\n",
    "            dogma_details = []\n",
    "            dogma_details = [mod for mod in row_info[\"dogma_attributes\"] if mod[\"attribute_id\"] in [50,64,204]]\n",
    "            for mod in dogma_details:\n",
    "                mod[\"contract_id\"] = row[\"contract_id\"]\n",
    "                mod[\"type_id\"] = row[\"type_id\"]\n",
    "                mod[\"item_id\"] = row[\"item_id\"]\n",
    "            item_stats.extend(dogma_details)\n",
    "        else:\n",
    "            if int(response.headers[\"X-Esi-Error-Limit-Remain\"]) < 20:\n",
    "                break\n",
    "            elif int(response.headers[\"X-Esi-Error-Limit-Remain\"]) < 50:\n",
    "                time.sleep(60)\n",
    "                \n",
    "df_pivoted = pd.json_normalize(item_stats).pivot(index=['contract_id', 'type_id', 'item_id'], columns='attribute_id', values='value').reset_index()\n",
    "df_pivoted = df_pivoted.rename_axis(None, axis=1)\n",
    "df_pivoted = df_pivoted.rename(columns={50: \"CPU\", 64: \"Damage\" , 204:\"ROF\"})\n",
    "output = pd.concat([contract_items_scanned, df_pivoted], ignore_index=True).drop_duplicates(keep=\"first\")\n",
    " \t\t\n",
    "output.to_parquet(\"./api_database/item_stats.parquet\")\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
